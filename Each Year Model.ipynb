{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score, confusion_matrix,roc_auc_score,roc_curve,auc,RocCurveDisplay, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import sketch\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6e5921-46ec-4ca5-afdf-27f45f6d1a65",
   "metadata": {},
   "source": [
    "## 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014 = pd.read_csv(r'C:\\Учеба\\Диплом\\2014_Financial_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99042f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014.rename(columns={\"2015 PRICE VAR [%]\": \"Price_Var\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8251c51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a51ff16d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014=pd.concat([data2014, pd.get_dummies(data2014[\"Sector\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c83b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014.drop(columns=[\"Sector\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb69db83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputer = KNNImputer(n_neighbors=5, weights='distance', metric='nan_euclidean', copy=True)\n",
    "# df_copy_clean = imputer.fit_transform(data2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9620f9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data2014 = pd.DataFrame(df_copy_clean,columns=data2014.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b832af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014.fillna(data2014.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ca3e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_correlated_features(X, threshold):\n",
    "  \n",
    "  # Calculate the correlation matrix\n",
    "  corr_matrix = X.corr().abs()\n",
    "\n",
    "  # Select upper triangle of correlation matrix\n",
    "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "  # Find features with correlation greater than threshold\n",
    "  to_drop = [column for column in upper.columns if any(upper[column] >= threshold)]\n",
    "\n",
    "  # Drop correlated features\n",
    "  X_reduced = X.drop(to_drop, axis=1)\n",
    "\n",
    "  return X_reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bea3df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2014.drop('Class', axis=1)\n",
    "y = data2014['Class']\n",
    "\n",
    "X_new = remove_correlated_features(X, threshold=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e915742",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "# 4. Train GradientBoostingClassifier\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a219e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd65bac-3fe2-4572-8955-463414eb6848",
   "metadata": {},
   "source": [
    "## 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf84ba1-234f-4ad4-97f0-f4f2cf08a5ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015 = pd.read_csv(r'C:\\Учеба\\Диплом\\2015_Financial_Data.csv')\n",
    "\n",
    "data2015.rename(columns={\"2016 PRICE VAR [%]\": \"Price_Var\"},inplace=True)\n",
    "data2015.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)\n",
    "data2015=pd.concat([data2015, pd.get_dummies(data2015[\"Sector\"])],axis=1)\n",
    "data2015.drop(columns=[\"Sector\"],inplace=True)\n",
    "data2015.fillna(data2015.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b196ffc-78df-43c5-8957-543e5b16ccbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2015.drop('Class', axis=1)\n",
    "y = data2015['Class']\n",
    "\n",
    "X_new = remove_correlated_features(X, threshold=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50cd456-d702-4dc0-af90-7a68827a252b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "# 4. Train GradientBoostingClassifier\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6728b6e2-54c7-4e08-af2c-9e3431a0b8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f85f2d9-0762-4b44-afda-02593ca8da30",
   "metadata": {},
   "source": [
    "## 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b832a9-465b-4bac-a97e-fa51ec60e630",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016 = pd.read_csv(r'C:\\Учеба\\Диплом\\2016_Financial_Data.csv')\n",
    "\n",
    "data2016.rename(columns={\"2017 PRICE VAR [%]\": \"Price_Var\"},inplace=True)\n",
    "data2016.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)\n",
    "data2016=pd.concat([data2016, pd.get_dummies(data2016[\"Sector\"])],axis=1)\n",
    "data2016.drop(columns=[\"Sector\"],inplace=True)\n",
    "data2016.fillna(data2016.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ba919b-95e4-4cd8-8ec9-6bf4b2b31b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "# 4. Train GradientBoostingClassifier\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d6dad1-5458-4be4-be07-8289b59734a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "625f9589-c8a0-4553-b4d6-d369994023fe",
   "metadata": {},
   "source": [
    "## 2017"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c89c91e-3708-4fb4-81f9-52b08ea276d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017 = pd.read_csv(r'C:\\Учеба\\Диплом\\2017_Financial_Data.csv')\n",
    "\n",
    "data2017.rename(columns={\"2018 PRICE VAR [%]\": \"Price_Var\"},inplace=True)\n",
    "data2017.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)\n",
    "data2017=pd.concat([data2017, pd.get_dummies(data2017[\"Sector\"])],axis=1)\n",
    "data2017.drop(columns=[\"Sector\"],inplace=True)\n",
    "data2017.fillna(data2017.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943ccaaf-0a19-4d26-b644-cbf97eb7b5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "# 4. Train GradientBoostingClassifier\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f7170f-b370-4d0f-a441-d5a337da610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ddd2e3-1bc5-4b5c-8d70-8a5888927717",
   "metadata": {},
   "source": [
    "## 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ede75b-fb60-475b-93b2-71add2311deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018 = pd.read_csv(r'C:\\Учеба\\Диплом\\2018_Financial_Data.csv')\n",
    "\n",
    "data2018.rename(columns={\"2019 PRICE VAR [%]\": \"Price_Var\"},inplace=True)\n",
    "data2018.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)\n",
    "data2018=pd.concat([data2018, pd.get_dummies(data2018[\"Sector\"])],axis=1)\n",
    "data2018.drop(columns=[\"Sector\"],inplace=True)\n",
    "data2018.fillna(data2018.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeee0a3-7301-476c-b2aa-066ac15f82db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "# 4. Train GradientBoostingClassifier\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674cc95-d905-42b9-808f-1ff50949d206",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12543157-a682-46a4-a7af-216170053a68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
