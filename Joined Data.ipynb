{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246fd760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score, confusion_matrix,roc_auc_score,roc_curve,auc,RocCurveDisplay, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "import sketch\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.impute import KNNImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a094c570",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014 = pd.read_csv(r'C:\\Учеба\\Диплом\\2014_Financial_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0374d288-cf43-43f5-8429-2ad1ef723dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2015 = pd.read_csv(r'C:\\Учеба\\Диплом\\2015_Financial_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4410b30-5414-46ca-a725-9e18e0ca078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2016 = pd.read_csv(r'C:\\Учеба\\Диплом\\2016_Financial_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e7171b-1a11-4bec-92b5-f2914d73e434",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2017 = pd.read_csv(r'C:\\Учеба\\Диплом\\2017_Financial_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce06bcf5-036f-4793-bfe1-b8986a30ba2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2018 = pd.read_csv(r'C:\\Учеба\\Диплом\\2018_Financial_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337c0519-7ca2-478b-b922-0af2b3e50edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014.rename(columns={\"2015 PRICE VAR [%]\": \"Price_Var\"},inplace=True)\n",
    "data2015.rename(columns={\"2016 PRICE VAR [%]\": \"Price_Var\"},inplace=True)\n",
    "data2016.rename(columns={\"2017 PRICE VAR [%]\": \"Price_Var\"},inplace=True)\n",
    "data2017.rename(columns={\"2018 PRICE VAR [%]\": \"Price_Var\"},inplace=True)\n",
    "data2018.rename(columns={\"2019 PRICE VAR [%]\": \"Price_Var\"},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618d5ecc-8b67-4b19-8865-bb2ad0741e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "stocks = list(set(data2014['Unnamed: 0']) & set(data2015['Unnamed: 0']) & set(data2016['Unnamed: 0']) & set(data2017['Unnamed: 0']) & set(data2018['Unnamed: 0']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4a18fc-d6cd-4332-821f-317220af6a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy = data2014[data2014[\"Unnamed: 0\"].isin(stocks)]\n",
    "data2015_copy = data2015[data2015[\"Unnamed: 0\"].isin(stocks)]\n",
    "data2016_copy = data2016[data2016[\"Unnamed: 0\"].isin(stocks)]\n",
    "data2017_copy = data2017[data2017[\"Unnamed: 0\"].isin(stocks)]\n",
    "data2018_copy = data2018[data2018[\"Unnamed: 0\"].isin(stocks)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d58fb-7115-4b98-aa04-2ab43780df58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [data2014_copy,data2015_copy,data2016_copy,data2017_copy,data2018_copy]:\n",
    "    print(len(i.columns[i.isna().sum() < 1000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e38436-e52d-40e5-8bb6-c11c41d0183c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rest_columns = data2014.columns[data2014.isna().sum() < 1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c88e9b-721e-40c4-8ff4-95ea0a16ab6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy2 = data2014_copy[rest_columns]\n",
    "data2015_copy2 = data2015_copy[rest_columns]\n",
    "data2016_copy2 = data2016_copy[rest_columns]\n",
    "data2017_copy2 = data2017_copy[rest_columns]\n",
    "data2018_copy2 = data2018_copy[rest_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7516ac9e-b45f-4c68-9d50-9926e6ee77f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy2.sort_values(by='Unnamed: 0',inplace=True,ignore_index=True)\n",
    "data2015_copy2.sort_values(by='Unnamed: 0',inplace=True,ignore_index=True)\n",
    "data2016_copy2.sort_values(by='Unnamed: 0',inplace=True,ignore_index=True)\n",
    "data2017_copy2.sort_values(by='Unnamed: 0',inplace=True,ignore_index=True)\n",
    "data2018_copy2.sort_values(by='Unnamed: 0',inplace=True,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd0754-4056-4650-89d6-0980d9f9b42d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy2.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)\n",
    "data2015_copy2.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)\n",
    "data2016_copy2.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)\n",
    "data2017_copy2.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)\n",
    "data2018_copy2.drop(columns=[\"Unnamed: 0\", \"Price_Var\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c449ebce-527c-4295-a7d9-d4400a15cb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy2=pd.concat([data2014_copy2, pd.get_dummies(data2014_copy2[\"Sector\"])],axis=1)\n",
    "data2015_copy2=pd.concat([data2015_copy2, pd.get_dummies(data2015_copy2[\"Sector\"])],axis=1)\n",
    "data2016_copy2=pd.concat([data2016_copy2, pd.get_dummies(data2016_copy2[\"Sector\"])],axis=1)\n",
    "data2017_copy2=pd.concat([data2017_copy2, pd.get_dummies(data2017_copy2[\"Sector\"])],axis=1)\n",
    "data2018_copy2=pd.concat([data2018_copy2, pd.get_dummies(data2018_copy2[\"Sector\"])],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99e64bc-e281-4ad2-99a6-c929f64b5d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy2.drop(columns=[\"Sector\"],inplace=True)\n",
    "data2015_copy2.drop(columns=[\"Sector\"],inplace=True)\n",
    "data2016_copy2.drop(columns=[\"Sector\"],inplace=True)\n",
    "data2017_copy2.drop(columns=[\"Sector\"],inplace=True)\n",
    "data2018_copy2.drop(columns=[\"Sector\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754e0180-888c-4390-a0de-5598ce34c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy2.fillna(data2014_copy2.median(),inplace=True)\n",
    "data2015_copy2.fillna(data2015_copy2.median(),inplace=True)\n",
    "data2016_copy2.fillna(data2016_copy2.median(),inplace=True)\n",
    "data2017_copy2.fillna(data2017_copy2.median(),inplace=True)\n",
    "data2018_copy2.fillna(data2018_copy2.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedcc554-cee0-420d-b5c5-77b685c38774",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_not_cor_cols(X, threshold):\n",
    "  \n",
    "  # Calculate the correlation matrix\n",
    "  corr_matrix = X.corr().abs()\n",
    "\n",
    "  # Select upper triangle of correlation matrix\n",
    "  upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "\n",
    "  # Find features with correlation greater than threshold\n",
    "  to_keep = [column for column in upper.columns if any(upper[column] < threshold)]\n",
    "\n",
    "  # Drop correlated features\n",
    "  # X_reduced = X.drop(to_keep, axis=1)\n",
    "\n",
    "  return to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b2adab-59fa-4344-9ccc-97abbcee35c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2014_copy2.drop('Class', axis=1)\n",
    "y = data2018_copy2['Class']\n",
    "\n",
    "not_cor_cols = get_not_cor_cols(X, threshold=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde984a5-6366-4753-9718-d00259a24021",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy3 = data2014_copy2[[*not_cor_cols,\"Class\"]]\n",
    "data2015_copy3 = data2015_copy2[[*not_cor_cols,\"Class\"]]\n",
    "data2016_copy3 = data2016_copy2[[*not_cor_cols,\"Class\"]]\n",
    "data2017_copy3 = data2017_copy2[[*not_cor_cols,\"Class\"]]\n",
    "data2018_copy3 = data2018_copy2[[*not_cor_cols,\"Class\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a860fcf-c165-4cbc-81fc-e8196a37b9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_copy4 = data2014_copy3.drop('Class', axis=1)\n",
    "data2015_copy4 = data2015_copy3.drop('Class', axis=1)\n",
    "data2016_copy4 = data2016_copy3.drop('Class', axis=1)\n",
    "data2017_copy4 = data2017_copy3.drop('Class', axis=1)\n",
    "data2018_copy4 = data2018_copy3.drop('Class', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ef64ac-9d5c-4213-8eda-aeba2ffa6131",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "X_2014_scaled = scaler.fit_transform(data2014_copy4)\n",
    "X_2015_scaled = scaler.fit_transform(data2015_copy4)\n",
    "X_2016_scaled = scaler.fit_transform(data2016_copy4)\n",
    "X_2017_scaled = scaler.fit_transform(data2017_copy4)\n",
    "X_2018_scaled = scaler.fit_transform(data2018_copy4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c6fc13-0855-470b-920b-6cde3f00d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = np.asarray([2.72**1,2.72**2,2.72**3,2.72**4,2.72**5])/sum([2.72**1,2.72**2,2.72**3,2.72**4,2.72**5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d47899-e025-419e-8ee0-44d240034175",
   "metadata": {},
   "outputs": [],
   "source": [
    "scs = [0.05,0.1,0.15,0.2,0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1c26ea-a68e-4bd9-92a9-f5061d452946",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = scs[0]*X_2014_scaled+scs[1]*X_2015_scaled+scs[2]*X_2016_scaled+scs[3]*X_2017_scaled+scs[4]*X_2018_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c83b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(final_df, y)\n",
    "\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "# 4. Train GradientBoostingClassifier\n",
    "\n",
    "\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6852c7-8006-4306-a296-1c089125b6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd395d4f-5fea-451e-88af-ffaca455017a",
   "metadata": {},
   "source": [
    "## Сделаем предикт на 2018 год по модели 2014"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b93f0f-b403-4a52-86fb-d688dc663887",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols2018 = X_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c2675-ca81-45eb-9f78-5d33e603356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2018.drop('Class', axis=1)\n",
    "y = data2018['Class']\n",
    "\n",
    "# X_new = remove_correlated_features(X, threshold=0.999)\n",
    "X_new = X[cols2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574ca453-a7cb-450d-b596-532b75abae4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb708f3-3dc8-48a9-a79f-e11dfd30e416",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_scaled)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "precision = precision_score(y, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y, y_pred, average='weighted')\n",
    "f1 = f1_score(y, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0e9f7c-d2a2-4646-9e47-47f208aba14a",
   "metadata": {},
   "source": [
    "## Объединим все года"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdf7940-a09d-44f1-9f40-d8cdd162ecb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014[\"Year\"]=2014\n",
    "data2015[\"Year\"]=2015\n",
    "data2016[\"Year\"]=2016\n",
    "data2017[\"Year\"]=2017\n",
    "data2018[\"Year\"]=2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f798e99-1f77-4837-94a1-9e9f3db6d9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=pd.concat([data2014,data2015,data2016,data2017,data2018])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84786520-291b-4326-8761-ae03f5d17857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_all.drop('Class', axis=1)\n",
    "y = data_all['Class']\n",
    "\n",
    "X_new = remove_correlated_features(X, threshold=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6c9c2a-e232-450a-952b-5dee9952e9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7bd8bc-f19d-4d8f-bcb0-55c52a915a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "# 4. Train GradientBoostingClassifier\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f88165-cc1e-452b-9da4-eae07b2c5c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b46177-52ed-49a9-a5ee-a2fb3b8438d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=model.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25be12-2ecc-490b-8a7c-6ac5e04f7b61",
   "metadata": {},
   "source": [
    "## Снова попробуем почистить данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc3e021-6db7-4489-add4-31245e63c3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_share_columns = list(filter(lambda x: \"per Share\" in x, list(data2014.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10915795-6224-4c8a-a6b9-78504477df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014.drop(columns=per_share_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7740fbc2-04bc-4fca-9941-4a24f4b41c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2014.drop('Class', axis=1)\n",
    "y = data2014['Class']\n",
    "\n",
    "X_new = remove_correlated_features(X, threshold=0.999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3e41f-e427-40ec-9790-d612482c304a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X_new)\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(X_scaled, y)\n",
    "\n",
    "# 3. Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)  # Adjust test_size and random_state as needed\n",
    "\n",
    "# 4. Train GradientBoostingClassifier\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c63c2-daf3-4494-9d23-94f7ae403a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af79aa0-aaf8-47b8-8200-024fb8baf0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "margin_columns = list(filter(lambda x: \"Margin\" in x, list(data2014.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04303a36-a8f8-4b9f-9ca6-2d2226154745",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014.drop(columns=margin_columns,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d274b5-083f-4704-8890-d926030c5a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014.drop(columns=['Price to Sales Ratio', 'Payout Ratio', 'priceToBookRatio', 'priceToSalesRatio'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "894e7f59-6340-4cc8-bc60-fa44eec78a2c",
   "metadata": {},
   "source": [
    "## Новые колонки со старой функцией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54be495b-6d66-4c1b-bd08-a9837628761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_var_col(year):\n",
    "    return f\"{year+1} PRICE VAR [%]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db438af9-c651-432c-8bee-dc2c08bbf562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_cf2_clean_rb_log(df: pd.DataFrame,price_var_col) -> pd.DataFrame:\n",
    "    clean_columns = list(filter(lambda x: \"per Share\" not in x and \"Margin\" not in x and \"growth\" not in x.lower(), list(df.columns)))\n",
    "\n",
    "    df_clean = df[clean_columns]\n",
    "    \n",
    "    sector_dict = {}\n",
    "    tmp = df_clean[['Sector', 'Class']]\n",
    "    for i in tmp['Sector'].drop_duplicates():\n",
    "        a=tmp[tmp['Sector']==i].value_counts().sort_index().values\n",
    "        sector_dict[i] = a[1]/sum(a)\n",
    "    df_copy = df_clean\n",
    "    df_copy['Sector'] = df_copy['Sector'].replace(sector_dict)\n",
    "    df_copy.drop(columns=['Unnamed: 0', price_var_col, 'Price to Sales Ratio', 'Payout Ratio', 'priceToBookRatio', 'priceToSalesRatio'],axis=1,inplace=True)\n",
    "    float_columns=list(df_copy.select_dtypes(include=['float64']).columns)\n",
    "    float_columns.remove('Sector')\n",
    "\n",
    "\n",
    "    df_for_loging = df_copy.drop(columns=['Class'])\n",
    "    \n",
    "    df_copy_pos = df_for_loging-df_for_loging.min()\n",
    "    \n",
    "    df_copy_pos_logged = np.log1p(df_copy_pos)\n",
    "\n",
    "    df_copy_pos_logged['Class'] = df_copy['Class']\n",
    "    \n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    df2 = df_copy_pos_logged\n",
    "    df2[float_columns] = scaler.fit_transform(df2[float_columns])\n",
    "    \n",
    "    lower = df2[float_columns].quantile(0.01)\n",
    "    greater = df2[float_columns].quantile(0.99)\n",
    "    df2[float_columns] = (df2[float_columns])[(df2[float_columns] >= lower) & (df2[float_columns] <= greater)]\n",
    "\n",
    "    df2.fillna(df2.median(),inplace=True)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7848e8ba-9d98-45e7-88ff-bf8f5224fef3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data2014_pp_rb = preprocess_cf2_clean_rb_log(data2014, get_price_var_col(2014))\n",
    "y=data2014_pp_rb['Class']\n",
    "X=data2014_pp_rb.drop(columns=['Class'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2,random_state=17)\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predict=model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predict))\n",
    "print(roc_auc_score(Y_test,predict))\n",
    "fpr, tpr, _ = roc_curve(Y_test,predict)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "RocCurveDisplay(fpr=fpr,tpr=tpr,roc_auc=roc_auc).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e93fc1-60f5-40c7-b3fb-0dd85d840107",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b771664f-c697-400f-8b61-bfa74ee8e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d4ab88-90d9-4f21-a94a-06144a0042de",
   "metadata": {},
   "outputs": [],
   "source": [
    "growth_columns = list(filter(lambda x: \"growth\" in x.lower(), list(data2014.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45571ec1-b401-46ce-9a20-a4b3eb7dfc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2014[growth_columns]\n",
    "X.fillna(X.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2121db09-543f-46b3-a59d-a10539e2733a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=len(growth_columns))\n",
    "pca.fit(X)\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbcc62a-d306-41e4-a14e-f31a48b30dcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create a PCA instance\n",
    "pca = PCA(n_components=6)  # Specify the number of components you want to retain\n",
    "\n",
    "# Apply PCA to the scaled data\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "# Create a new dataframe to store the PCA results\n",
    "df_pca_result_growth = pd.DataFrame(data=pca_result, columns=['GR1', 'GR2', 'GR3', 'GR4', 'GR5', 'GR6'])\n",
    "\n",
    "# Concatenate the PCA results with the original dataframe\n",
    "#df_final = pd.concat([data2014_pp_rb, df_pca_result], axis=1)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Print the principal components' loadings or coefficients\n",
    "print(\"Principal Components' Loadings:\")\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f174fe-d6cd-4f8e-9340-854172200718",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_result_growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42150421-143b-4d23-9e8b-f98591320425",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_columns = list(filter(lambda x: \"ratio\" in x.lower(), list(data2014.columns)))\n",
    "ratio_columns = list(filter(lambda x: \"Price to Sales Ratio\" not in x and \"Payout Ratio\" not in x and \"priceToBookRatio\" not in x and \"priceToSalesRatio\" not in x, ratio_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11db684-2a90-4869-badb-b8fe4d88b4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2014[ratio_columns]\n",
    "X.fillna(X.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b41f4a-ba63-4730-9d75-1084c2f6b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=len(ratio_columns))\n",
    "pca.fit(X)\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98e6e0b-f369-4b12-9aed-f8d8daca3b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA instance\n",
    "pca = PCA(n_components=3)  # Specify the number of components you want to retain\n",
    "\n",
    "# Apply PCA to the scaled data\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "# Create a new dataframe to store the PCA results\n",
    "df_pca_result_ratio = pd.DataFrame(data=pca_result, columns=['RAT1', 'RAT2', 'RAT3'])\n",
    "\n",
    "# Concatenate the PCA results with the original dataframe\n",
    "#df_final = pd.concat([data2014_pp_rb, df_pca_result], axis=1)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Print the principal components' loadings or coefficients\n",
    "print(\"Principal Components' Loadings:\")\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b94b79-154d-49ef-a78b-13e665062cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_result_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64df852e-86a1-456d-a40b-66f457d503d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_share_columns = list(filter(lambda x: \"per Share\" in x, list(data2014.columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c525b90-baf9-4492-8b0e-ed14ca0e269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data2014[per_share_columns]\n",
    "X.fillna(X.median(),inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a990c-fa05-49db-a5f5-2be049ded9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform PCA\n",
    "pca = PCA(n_components=len(per_share_columns))\n",
    "pca.fit(X)\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "\n",
    "# Calculate cumulative explained variance\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Plot cumulative explained variance\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, marker='o')\n",
    "plt.xlabel('Number of Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.title('Cumulative Explained Variance vs. Number of Components')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ac8cd5-49db-4ae2-9ac1-687a1fb4e432",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a PCA instance\n",
    "pca = PCA(n_components=5)  # Specify the number of components you want to retain\n",
    "\n",
    "# Apply PCA to the scaled data\n",
    "pca_result = pca.fit_transform(X)\n",
    "\n",
    "# Create a new dataframe to store the PCA results\n",
    "df_pca_result_per_share = pd.DataFrame(data=pca_result, columns=['PS1', 'PS2', 'PS3', 'PS4', 'PS5'])\n",
    "\n",
    "# Concatenate the PCA results with the original dataframe\n",
    "#df_final = pd.concat([data2014_pp_rb, df_pca_result], axis=1)\n",
    "\n",
    "# Print the explained variance ratio\n",
    "print(\"Explained Variance Ratio:\", pca.explained_variance_ratio_)\n",
    "\n",
    "# Print the principal components' loadings or coefficients\n",
    "print(\"Principal Components' Loadings:\")\n",
    "print(pca.components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3eec14f-a5af-433c-9386-feb06b0fc685",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_result_per_share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d6dc3c-cdc8-4128-bc31-dbc1013168d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_cf2_clean_rb_log_new(df: pd.DataFrame,price_var_col) -> pd.DataFrame:\n",
    "    clean_columns = list(filter(lambda x: \"per Share\" not in x and \"ratio\" not in x.lower() and \"growth\" not in x.lower(), list(df.columns)))\n",
    "\n",
    "    df_clean = df[clean_columns]\n",
    "    \n",
    "    sector_dict = {}\n",
    "    tmp = df_clean[['Sector', 'Class']]\n",
    "    for i in tmp['Sector'].drop_duplicates():\n",
    "        a=tmp[tmp['Sector']==i].value_counts().sort_index().values\n",
    "        sector_dict[i] = a[1]/sum(a)\n",
    "    df_copy = df_clean\n",
    "    df_copy['Sector'] = df_copy['Sector'].replace(sector_dict)\n",
    "    df_copy.drop(columns=['Unnamed: 0', price_var_col],axis=1,inplace=True)\n",
    "    float_columns=list(df_copy.select_dtypes(include=['float64']).columns)\n",
    "    float_columns.remove('Sector')\n",
    "\n",
    "\n",
    "    df_for_loging = df_copy.drop(columns=['Class'])\n",
    "    \n",
    "    df_copy_pos = df_for_loging-df_for_loging.min()\n",
    "    \n",
    "    df_copy_pos_logged = np.log1p(df_copy_pos)\n",
    "\n",
    "    df_copy_pos_logged['Class'] = df_copy['Class']\n",
    "    \n",
    "\n",
    "    scaler = RobustScaler()\n",
    "    df2 = pd.concat([df_copy_pos_logged, df_pca_result_per_share, df_pca_result_growth, df_pca_result_ratio], axis=1)\n",
    "    df2[float_columns] = scaler.fit_transform(df2[float_columns])\n",
    "    \n",
    "    lower = df2[float_columns].quantile(0.01)\n",
    "    greater = df2[float_columns].quantile(0.99)\n",
    "    df2[float_columns] = (df2[float_columns])[(df2[float_columns] >= lower) & (df2[float_columns] <= greater)]\n",
    "\n",
    "    df2.fillna(df2.median(),inplace=True)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc150591-af4f-4d70-9022-165a84ebb5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2014_pp_rb = preprocess_cf2_clean_rb_log_new(data2014, get_price_var_col(2014))\n",
    "y=data2014_pp_rb['Class']\n",
    "X=data2014_pp_rb.drop(columns=['Class'])\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3,random_state=17)\n",
    "\n",
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "predict=model.predict(X_test)\n",
    "print(confusion_matrix(Y_test, predict))\n",
    "print(roc_auc_score(Y_test,predict))\n",
    "fpr, tpr, _ = roc_curve(Y_test,predict)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "RocCurveDisplay(fpr=fpr,tpr=tpr,roc_auc=roc_auc).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de4517b-5a04-46c6-8df4-3bf3b57e675e",
   "metadata": {},
   "source": [
    "## кластеризация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ca3e56-f013-4716-bae8-fc9807bdd141",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne = TSNE(random_state=17)\n",
    "tsne_representation = tsne.fit_transform(X_2018_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8421d11a-3bf8-4e17-b8a1-1c1d314275fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(tsne_representation[:, 0], tsne_representation[:, 1], c=y, s=5);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4251db-a14d-438b-95a9-25494327f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31681189-970a-4c6a-941e-f69e36b567a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "model = TSNE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ee0722-ca5b-440e-bbb5-a136334d4605",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = model.fit_transform(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54df9ff-0666-4536-b251-c62e44fc797e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = transformed[:, 0]\n",
    "y_axis = transformed[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d427b3f1-d1de-46be-adf7-f3644259d3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x_axis, y_axis, c =\"red\", s =5)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aef8a9-7153-4d71-bd18-a7ce2b145907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score, calinski_harabasz_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2338deb5-2ca4-4e07-8a08-e977f92c0a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ag_silhouette= []\n",
    "db_score=[]\n",
    "calinski_score=[]\n",
    "for i in range(1, 11):\n",
    "    dbscan = DBSCAN(eps=i, min_samples=7).fit(transformed)\n",
    "    preds = dbscan.labels_\n",
    "    \n",
    "    silhouette = silhouette_score(transformed,preds)\n",
    "    ag_silhouette.append(silhouette)\n",
    "    print(\"Silhouette score for eps {}: {}\".format(i,silhouette))\n",
    "    \n",
    "    db = davies_bouldin_score(transformed,preds)\n",
    "    db_score.append(db)\n",
    "    print(\"Davies Bouldin score for eps {}: {}\".format(i,db))\n",
    "\n",
    "    calinski = calinski_harabasz_score(transformed,preds)\n",
    "    calinski_score.append(calinski)\n",
    "    print(\"Calinski harabasz score for eps {}: {}\".format(i,calinski))\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae6c0b3-b26f-448d-ab62-0cc77279fc86",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"DBSCAN model Silhouette score \\nfor determining eps\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(1,11)],y=ag_silhouette,s=150,edgecolor='k')\n",
    "plt.plot([i for i in range(1,11)],ag_silhouette)\n",
    "plt.grid(True)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"eps\",fontsize=14)\n",
    "plt.ylabel(\"DBSCAN Silhouette score\",fontsize=15)\n",
    "plt.xticks([i for i in range(1,11)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b9a791-50ad-481f-9047-fa3f73bfbce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"DBSCAN model Davies Bouldin score \\nfor determining eps\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(1,11)],y=db_score,s=150,edgecolor='k')\n",
    "plt.plot([i for i in range(1,11)],db_score)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"eps\",fontsize=14)\n",
    "plt.ylabel(\"DBSCAN Davies Bouldin score\",fontsize=15)\n",
    "plt.xticks([i for i in range(1,11)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff2589-a9fb-426a-a7b0-a67a6999cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"DBSCAN model Calinski harabasz score \\nfor determining eps\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(1,11)],y=calinski_score,s=150,edgecolor='k')\n",
    "plt.plot([i for i in range(1,11)],calinski_score)\n",
    "plt.grid(True)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"eps\",fontsize=14)\n",
    "plt.ylabel(\"DBSCAN Calinski harabasz score\",fontsize=15)\n",
    "plt.xticks([i for i in range(1,11)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebbada3-8acd-40d7-88bf-6f991d99b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"DBSCAN model Davies Bouldin score \\nfor determining eps\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(1,11)],y=db_score,s=150,edgecolor='k')\n",
    "plt.plot([i for i in range(1,11)],db_score)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"eps\",fontsize=14)\n",
    "plt.ylabel(\"DBSCAN Davies Bouldin score\",fontsize=15)\n",
    "plt.xticks([i for i in range(1,11)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e403038-8db3-48dc-b8a4-0c779b78b053",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7,4))\n",
    "plt.title(\"DBSCAN model Calinski harabasz score \\nfor determining min_samples\\n\",fontsize=16)\n",
    "plt.scatter(x=[i for i in range(1, 150, 15)],y=calinski_score,s=150,edgecolor='k')\n",
    "plt.plot([i for i in range(1, 150, 15)],calinski_score)\n",
    "plt.grid(True)\n",
    "plt.grid(True)\n",
    "plt.xlabel(\"Min_samples\",fontsize=14)\n",
    "plt.ylabel(\"DBSCAN Calinski harabasz score\",fontsize=15)\n",
    "plt.xticks([i for i in range(1, 150, 15)],fontsize=14)\n",
    "plt.yticks(fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd715ca-3815-4f1d-b869-9b8e22b43387",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds4 = DBSCAN().fit(transformed).labels_\n",
    "\n",
    "n_clusters_ = len(set(preds4)) - (1 if -1 in preds4 else 0)\n",
    "n_noise_ = list(preds4).count(-1)\n",
    "print(f'Estimated number of clusters: {n_clusters_}')\n",
    "print(f'Estimated number of noise points: {n_noise_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b61557-0e7e-4fb7-9ec8-6bc61051a978",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
