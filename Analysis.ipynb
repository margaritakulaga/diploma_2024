{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9bf0a6-8231-406b-b458-c49138211cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Plotting\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Finance related operations\n",
    "from pandas_datareader import data\n",
    "\n",
    "# Import this to silence a warning when converting data column of a dataframe on the fly\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cdf7f4-7df0-4480-892e-3b53d0aec514",
   "metadata": {},
   "source": [
    "## LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0019e526-8c99-4efb-a6c3-1db31fc2acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(r'C:\\Учеба\\Диплом\\2014_Financial_Data.csv')\n",
    "\n",
    "# Drop rows with no information\n",
    "df.dropna(how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d332e6f-0dbd-4ded-b355-c3c0009d1d95",
   "metadata": {},
   "source": [
    "## FIRST LOOK AT THE DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeca1cb5-8348-4cbd-82f2-790cb2df568d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info about dataset\n",
    "df.info()\n",
    "\n",
    "# Describe dataset variables\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8974fc-b289-407e-949e-03761092111d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class distribution\n",
    "df_class = df['Class'].value_counts()\n",
    "sns.barplot(x=df_class.index, y=df_class.values)\n",
    "plt.title('CLASS COUNT', fontsize=20)\n",
    "plt.show()\n",
    "\n",
    "# Plot sector distribution\n",
    "df_sector = df['Sector'].value_counts()\n",
    "sns.barplot(x=df_sector.index, y=df_sector.values)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('SECTORS COUNT', fontsize=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be115ab-a08d-4c51-911f-b633b8cec241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the columns we need in this step from the dataframe\n",
    "df_ = df.loc[:, ['Sector', '2015 PRICE VAR [%]']]\n",
    "\n",
    "# Get list of sectors\n",
    "sector_list = df_['Sector'].unique()\n",
    "\n",
    "# Plot the percent price variation for each sector\n",
    "for sector in sector_list:\n",
    "    \n",
    "    temp = df_[df_['Sector'] == sector]\n",
    "\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.plot(temp['2015 PRICE VAR [%]'])\n",
    "    plt.title(sector.upper(), fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1732004-de90-472d-a959-3e20dca04303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "# Get stocks that increased more than 500%\n",
    "gain = 500\n",
    "top_gainers = df[df['2015 PRICE VAR [%]'] >= gain]\n",
    "top_gainers = top_gainers['2015 PRICE VAR [%]'].sort_values(ascending=False)\n",
    "print(f'{len(top_gainers)} STOCKS with more than {gain}% gain.')\n",
    "print()\n",
    "\n",
    "# Set\n",
    "date_start = '2015-01-01'\n",
    "date_end = '2015-12-31'\n",
    "tickers = top_gainers.index.values.tolist()\n",
    "ticker_row = []\n",
    "for ticker in tickers:\n",
    "    row_value = df[df['2015 PRICE VAR [%]'].index == ticker].iloc[0]['Unnamed: 0']\n",
    "    ticker_row.append(row_value)\n",
    "  \n",
    "for value in ticker_row:\n",
    "    # Pull daily prices for each ticker from Yahoo Finance\n",
    "    daily_price = yf.download(value, date_start, date_end)\n",
    "    \n",
    "    # Plot prices with volume\n",
    "    fig, (ax0, ax1) = plt.subplots(2, 1, gridspec_kw={'height_ratios': [3, 1]})\n",
    "    \n",
    "    ax0.plot(daily_price['Adj Close'])\n",
    "    ax0.set_title(value, fontsize=18)\n",
    "    ax0.set_ylabel('Daily Adj Close $', fontsize=14)\n",
    "    ax1.plot(daily_price['Volume'])\n",
    "    ax1.set_ylabel('Volume', fontsize=14)\n",
    "\n",
    "    fig.align_ylabels(ax1)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e5962b-45bd-4d5a-8fd2-925ff1a38d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop those stocks with inorganic gains\n",
    "inorganic_stocks = tickers[:-2] # all except last 2\n",
    "df.drop(inorganic_stocks, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82ef179-4d61-47e9-9d43-c7b17fe4933a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check again for gain-outliers\n",
    "df_ = df.loc[:, ['Sector', '2015 PRICE VAR [%]']]\n",
    "sector_list = df_['Sector'].unique()\n",
    "\n",
    "for sector in sector_list:\n",
    "    \n",
    "    temp = df_[df_['Sector'] == sector] # get all data for one sector\n",
    "\n",
    "    plt.figure(figsize=(30,5))\n",
    "    plt.plot(temp['2015 PRICE VAR [%]'])\n",
    "    plt.title(sector.upper(), fontsize=20)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be95c86b-06db-43a2-ba83-9bf94537aeb0",
   "metadata": {},
   "source": [
    "## HANDLE MISSING VALUES, 0-VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cbcda1-4a2e-423b-98f7-470c56588aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns relative to classification, we will use them later\n",
    "class_data = df.loc[:, ['Class', '2015 PRICE VAR [%]']]\n",
    "df.drop(['Class', '2015 PRICE VAR [%]'], inplace=True, axis=1)\n",
    "\n",
    "# Plot initial status of data quality in terms of nan-values and zero-values\n",
    "nan_vals = df.isna().sum()\n",
    "zero_vals = df.isin([0]).sum()\n",
    "ind = np.arange(df.shape[1])\n",
    "\n",
    "plt.figure(figsize=(50,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('INITIAL INFORMATION ABOUT DATASET', fontsize=22)\n",
    "plt.bar(ind, nan_vals.values.tolist())\n",
    "plt.ylabel('NAN-VALUES COUNT', fontsize=18)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(ind, zero_vals.values.tolist())\n",
    "plt.ylabel('ZERO-VALUES COUNT', fontsize=18)\n",
    "plt.xticks(ind, nan_vals.index.values, rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4df708-586c-4ccc-820e-ab56021b3bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find count and percent of nan-values, zero-values\n",
    "total_nans = df.isnull().sum().sort_values(ascending=False)\n",
    "percent_nans = (df.isnull().sum()/df.isnull().count() * 100).sort_values(ascending=False)\n",
    "total_zeros = df.isin([0]).sum().sort_values(ascending=False)\n",
    "percent_zeros = (df.isin([0]).sum()/df.isin([0]).count() * 100).sort_values(ascending=False)\n",
    "df_nans = pd.concat([total_nans, percent_nans], axis=1, keys=['Total NaN', 'Percent NaN'])\n",
    "df_zeros = pd.concat([total_zeros, percent_zeros], axis=1, keys=['Total Zeros', 'Percent Zeros'])\n",
    "\n",
    "# Graphical representation\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(np.arange(30), df_nans['Percent NaN'].iloc[:30].values.tolist())\n",
    "plt.xticks(np.arange(30), df_nans['Percent NaN'].iloc[:30].index.values.tolist(), rotation=90)\n",
    "plt.ylabel('NAN-Dominance [%]', fontsize=18)\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(np.arange(30), df_zeros['Percent Zeros'].iloc[:30].values.tolist())\n",
    "plt.xticks(np.arange(30), df_zeros['Percent Zeros'].iloc[:30].index.values.tolist(), rotation=90)\n",
    "plt.ylabel('ZEROS-Dominance [%]', fontsize=18)\n",
    "plt.grid(alpha=0.3, axis='y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4969a0-3e2f-4bac-8f40-0415b70c15a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find reasonable threshold for nan-values situation\n",
    "test_nan_level = 0.5\n",
    "print(df_nans.quantile(test_nan_level))\n",
    "_, thresh_nan = df_nans.quantile(test_nan_level)\n",
    "\n",
    "# Find reasonable threshold for zero-values situation\n",
    "test_zeros_level = 0.6\n",
    "print(df_zeros.quantile(test_zeros_level))\n",
    "_, thresh_zeros = df_zeros.quantile(test_zeros_level)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e66ae-17e8-4c06-9903-6a062c5ee3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean dataset applying thresholds for both zero values and NaN values\n",
    "print(f'INITIAL NUMBER OF VARIABLES: {df.shape[1]}')\n",
    "print()\n",
    "\n",
    "df_test1 = df.drop(df_nans[df_nans['Percent NaN'] > thresh_nan].index, axis=1)\n",
    "print(f'NUMBER OF VARIABLES AFTER NaN THRESHOLD {thresh_nan:.2f}%: {df_test1.shape[1]}')\n",
    "print()\n",
    "\n",
    "df_zeros_postnan = df_zeros.drop(df_nans[df_nans['Percent NaN'] > thresh_nan].index, axis=0)\n",
    "df_test2 = df_test1.drop(df_zeros_postnan[df_zeros_postnan['Percent Zeros'] > thresh_zeros].index, axis=1)\n",
    "print(f'NUMBER OF VARIABLES AFTER Zeros THRESHOLD {thresh_zeros:.2f}%: {df_test2.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9034cb-0cac-419b-8ba4-15c8661eb6f1",
   "metadata": {},
   "source": [
    "## CORRELATION MATRIX, CHECK MISSING VALUES AGAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99f6d49-5488-42b8-a5a6-85c762b860b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude non-numeric columns\n",
    "numeric_columns = df_test2.select_dtypes(include=np.number).columns\n",
    "df_numeric = df_test2[numeric_columns]\n",
    "\n",
    "# Plot correlation matrix\n",
    "fig, ax = plt.subplots(figsize=(20, 15))\n",
    "sns.heatmap(df_numeric.corr(), annot=False, cmap='YlGnBu', vmin=-1, vmax=1, center=0, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1fbdc0-0240-4760-b09c-3e23a95e29ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New check on nan values\n",
    "plt.figure(figsize=(50,10))\n",
    "\n",
    "plt.subplot(2,1,1)\n",
    "plt.title('INFORMATION ABOUT DATASET - CLEANED NAN + ZEROS', fontsize=22)\n",
    "plt.bar(np.arange(df_test2.shape[1]), df_test2.isnull().sum())\n",
    "plt.ylabel('NAN-VALUES COUNT', fontsize=18)\n",
    "\n",
    "plt.subplot(2,1,2)\n",
    "plt.bar(np.arange(df_test2.shape[1]), df_test2.isin([0]).sum())\n",
    "plt.ylabel('ZERO-VALUES COUNT', fontsize=18)\n",
    "plt.xticks(np.arange(df_test2.shape[1]), df_test2.columns.values, rotation=90)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33cc1339-bb7b-4b69-93b0-c5b3d089679a",
   "metadata": {},
   "source": [
    "## HANDLE EXTREME VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d8d07c-b217-42d1-9876-8db489bb01de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze dataframe\n",
    "df_test2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932b1ce2-3e92-44e4-b211-4c686d37af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cut outliers\n",
    "top_quantiles = df_test2[numeric_columns].quantile(0.97)\n",
    "outliers_top = (df_test2[numeric_columns] > top_quantiles)\n",
    "\n",
    "low_quantiles = df_test2[numeric_columns].quantile(0.03)\n",
    "outliers_low = (df_test2[numeric_columns] < low_quantiles)\n",
    "\n",
    "df_test2[numeric_columns] = df_test2[numeric_columns].mask(outliers_top, top_quantiles, axis=1)\n",
    "df_test2[numeric_columns] = df_test2[numeric_columns].mask(outliers_low, low_quantiles, axis=1)\n",
    "\n",
    "# Take a look at the dataframe post-outliers cut\n",
    "df_test2.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfaebc05-4c0a-489f-9e02-17145fbaafaf",
   "metadata": {},
   "source": [
    "## FILL MISSING VALUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca47e3-43f3-468e-8207-3b0e9e727236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace nan-values with mean value of column, considering each sector individually.\n",
    "df_test2[numeric_columns] = df_test2.groupby('Sector')[numeric_columns].transform(lambda x: x.fillna(x.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014ef018-a9b2-46f3-8908-670e5577eb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numeric = df_test2[numeric_columns]\n",
    "\n",
    "# Plot correlation matrix of output dataset\n",
    "fig, ax = plt.subplots(figsize=(20,15)) \n",
    "sns.heatmap(df_numeric.corr(), annot=False, cmap='YlGnBu', vmin=-1, vmax=1, center=0, ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f02c94-21fd-4abd-8435-8332707a6931",
   "metadata": {},
   "source": [
    "## ADD TARGET DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "666d1e15-cbfd-47cd-a2cd-ae99d366f964",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Add back the classification columns\n",
    "df_out = df_test2.join(class_data)\n",
    "\n",
    "# Print information about dataset\n",
    "df_out.info()\n",
    "df_out.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de00eb-9919-469a-8fbc-add95164a892",
   "metadata": {},
   "source": [
    "## Data Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6b0fd8-bec6-413c-8894-c7a5cc3f5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544647c-4bac-48da-9d04-1c3df1002eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_out.drop(columns=['Unnamed: 0', '2015 PRICE VAR [%]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd29a5-11f0-41d6-bf35-234e1966232c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sector_dict = {}\n",
    "for i in df_final['Sector'].drop_duplicates():\n",
    "        test = df_final[df_final['Sector'] == i].value_counts().sort_index().values\n",
    "        sector_dict[i] = test[1]/sum(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4d9620-f450-44e4-9634-8caf9e1130d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_copy = df_final\n",
    "\n",
    "df_final_copy['Sector'] = df_final_copy['Sector'].replace(sector_dict)\n",
    "sector = df_final_copy['Sector']\n",
    "\n",
    "df_no_sector = df_final_copy.drop(columns=['Sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2153380-931f-45b5-82ba-255d3cb02596",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_scale = df_no_sector.drop('Class', axis=1)\n",
    "y = df_final_copy['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f26814-8b7f-47ea-934a-d04e7302c16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "df_scaled = scaler.fit_transform(df_to_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a0d32-ba9f-47c6-adce-a746ce95433c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result = np.hstack((df_scaled, sector.values[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816cae98-07b4-462c-b36c-a2617ee0bbd0",
   "metadata": {},
   "source": [
    "## Build Model and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e3caf3-0ba1-4e64-83b6-d58aaa649a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score, confusion_matrix,roc_auc_score,roc_curve,auc,RocCurveDisplay, mean_squared_error\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493da516-feb0-437f-95c6-5e1609588726",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=0)\n",
    "X_resampled, y_resampled = ros.fit_resample(df_result, y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c873e8b-4472-4d20-988e-8ddfbcc7fa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'learning_rate': 0.01, 'max_depth': 7, 'n_estimators': 200, 'subsample': 0.5}\n",
    "\n",
    "model = GradientBoostingClassifier(**best_params)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1cfbef-1809-4972-839e-ae75f113d324",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 2. Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted')  # Adjust 'average' parameter as needed\n",
    "recall = recall_score(y_test, y_pred, average='weighted')\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "# 3. Print the metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-score:\", f1)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04c29b1-f570-4dcd-93f4-85c618a6e3ba",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e7a6e0-6072-4daa-824b-98dba0f62fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5db6b4-10ec-463f-927c-3fc9d760dc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_for_reg = df_out.drop(columns=['Unnamed: 0', 'Class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b703b91-2f55-460b-b90a-d32877c6e032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_sector_for_reg = df_final_for_reg.drop(columns=['Sector'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac63ebc-2b06-4ef4-a998-186fe8d29362",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_scale_for_reg = df_no_sector_for_reg.drop('2015 PRICE VAR [%]', axis=1)\n",
    "y = df_final_for_reg['2015 PRICE VAR [%]']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4460306-530f-4b6a-be11-e1ee4df10c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = RobustScaler()\n",
    "\n",
    "df_scaled_for_reg = scaler.fit_transform(df_to_scale_for_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484c551b-7079-49d6-8738-8ab4f3a8b8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result_for_reg = np.hstack((df_scaled_for_reg, sector.values[:, np.newaxis]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb3ba7-97ce-4883-ae04-058f325bae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_result_for_reg, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fcb41-b1aa-4be8-b8a3-61d8405362ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=GradientBoostingRegressor(max_depth=6)\n",
    "model.fit(X_train, y_train)\n",
    "predict=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7a92fc-8880-435b-8e08-70c768361e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818c4bc8-d76d-4a58-9796-9e813c65dd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score(y_test, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcaf14f8-c88c-436d-96f3-62595bedd78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_mean = sum(y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c99f73b-7c76-4a1c-b9a9-f2fff735151a",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_tot = sum((y_test.values[i] - y_mean)**2 for i in range(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5620a4-ab40-4afb-8340-47d41e24488d",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS_res = sum((predict[i] - y_mean)**2 for i in range(len(y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b9ced6-35fe-43a3-81d8-334d7a672d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "R2 = 1 - (SS_res / SS_tot)\n",
    "print(f\"R²: {R2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4fb8032-541b-4bf6-bc93-a86451e18338",
   "metadata": {},
   "source": [
    "## More analysys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5296de5-fef4-45b9-a27d-b37002eb429d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1624a7b-4583-4f3b-adf7-0982e0149715",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014 = pd.read_csv(r'C:\\Учеба\\Диплом\\2014_Financial_Data.csv')\n",
    "df_2015 = pd.read_csv(r'C:\\Учеба\\Диплом\\2015_Financial_Data.csv')\n",
    "df_2016 = pd.read_csv(r'C:\\Учеба\\Диплом\\2016_Financial_Data.csv')\n",
    "df_2017 = pd.read_csv(r'C:\\Учеба\\Диплом\\2017_Financial_Data.csv')\n",
    "df_2018 = pd.read_csv(r'C:\\Учеба\\Диплом\\2018_Financial_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b39ccb-8674-4865-b371-efdf0705a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of data for Year 2014 is {}\".format(df_2014.shape))\n",
    "print(\"Shape of data for Year 2015 is {}\".format(df_2015.shape))\n",
    "print(\"Shape of data for Year 2016 is {}\".format(df_2016.shape))\n",
    "print(\"Shape of data for Year 2017 is {}\".format(df_2017.shape))\n",
    "print(\"Shape of data for Year 2018 is {}\".format(df_2018.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f0217fb-a3a2-454b-89b0-df8f746d9d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data missing information for 2014 year\n",
    "data_info = pd.concat([pd.DataFrame(df_2014.dtypes).T.rename(index={0: 'column type'}),\n",
    "                      pd.DataFrame(df_2014.isnull().sum()).T.rename(index={0: 'null values (nb)'}),\n",
    "                      pd.DataFrame(df_2014.isnull().sum() / df_2014.shape[0] * 100).T.rename(index={0: 'null values (%)'})])\n",
    "\n",
    "display(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d564abda-5728-468c-ad06-92bd215cff5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data missing information for 2015 year\n",
    "data_info = pd.concat([pd.DataFrame(df_2015.dtypes).T.rename(index={0: 'column type'}),\n",
    "                      pd.DataFrame(df_2015.isnull().sum()).T.rename(index={0: 'null values (nb)'}),\n",
    "                      pd.DataFrame(df_2015.isnull().sum() / df_2015.shape[0] * 100).T.rename(index={0: 'null values (%)'})])\n",
    "\n",
    "display(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f582af73-6004-4b0c-be77-0ff724230bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data missing information for 2016 year\n",
    "data_info = pd.concat([pd.DataFrame(df_2016.dtypes).T.rename(index={0: 'column type'}),\n",
    "                      pd.DataFrame(df_2016.isnull().sum()).T.rename(index={0: 'null values (nb)'}),\n",
    "                      pd.DataFrame(df_2016.isnull().sum() / df_2016.shape[0] * 100).T.rename(index={0: 'null values (%)'})])\n",
    "\n",
    "display(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be758e5-6248-499a-9220-1cd91d0b8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data missing information for 2017 year\n",
    "data_info = pd.concat([pd.DataFrame(df_2017.dtypes).T.rename(index={0: 'column type'}),\n",
    "                      pd.DataFrame(df_2017.isnull().sum()).T.rename(index={0: 'null values (nb)'}),\n",
    "                      pd.DataFrame(df_2017.isnull().sum() / df_2017.shape[0] * 100).T.rename(index={0: 'null values (%)'})])\n",
    "\n",
    "display(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb6bbfd-1093-4ded-978f-f4cea58efde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data missing information for 2018 year\n",
    "data_info = pd.concat([pd.DataFrame(df_2018.dtypes).T.rename(index={0: 'column type'}),\n",
    "                      pd.DataFrame(df_2018.isnull().sum()).T.rename(index={0: 'null values (nb)'}),\n",
    "                      pd.DataFrame(df_2018.isnull().sum() / df_2018.shape[0] * 100).T.rename(index={0: 'null values (%)'})])\n",
    "\n",
    "display(data_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50303feb-bc94-4a63-a29d-43dfd00e2cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2014.fillna(0,inplace=True)\n",
    "df_2015.fillna(0,inplace=True)\n",
    "df_2016.fillna(0,inplace=True)\n",
    "df_2017.fillna(0,inplace=True)\n",
    "df_2018.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b82d80-39bc-4a9e-8a9e-d848af5b31f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Considering Procter & Gamble company only \n",
    "df_2014 = df_2014[df_2014['Unnamed: 0'] =='PG' ]\n",
    "df_2015 = df_2015[df_2015['Unnamed: 0'] =='PG' ]\n",
    "df_2016 = df_2016[df_2016['Unnamed: 0'] =='PG' ]\n",
    "df_2017 = df_2017[df_2017['Unnamed: 0'] =='PG' ]\n",
    "df_2018 = df_2018[df_2018['Unnamed: 0'] =='PG' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2cd450-ecf6-4c40-9e21-20eced809c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_2014,df_2015,df_2016,df_2017,df_2018])\n",
    "df.fillna(0,inplace=True)\n",
    "df.index = [2014,2015,2016,2017,2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14348139-b3a4-424a-8ede-32e665846af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean of Quick Ratio for P&G last 5 year is {:.2f} \".format(df['quickRatio'].mean()))\n",
    "plt.figure(figsize=(15, 7))\n",
    "df['quickRatio'].plot.bar(color='g')\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Quick Ratio')\n",
    "plt.title('Quick Ratio analysis P&G ')\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8457f28b-a6c2-41b2-bd83-a2244dfcb999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Current ratio\n",
    "print(\"Mean of Current Ratio for P&G last 5 year is {:.2f} \".format(df['currentRatio'].mean()))\n",
    "plt.figure(figsize=(15, 7))\n",
    "df['currentRatio'].plot.bar()\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Current Ratio')\n",
    "plt.title('Current Ratio analysis P&G ')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c2a34-e10d-4c25-a1ee-008aeff8dc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debt to Equity ratio\n",
    "print(\"Mean of Debt to Equity  Ratio for P&G last 5 year is {:.2f} \".format(df['debtEquityRatio'].mean()))\n",
    "plt.figure(figsize=(15, 7))\n",
    "df['debtEquityRatio'].plot.bar()\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('debtEquity Ratio')\n",
    "plt.title('Debt Equity Ratio analysis P&G ')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0141420-99dc-4bb9-bf85-db8f352afb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return on equity\n",
    "print(\"Mean of Inventory Turnover for P&G last 5 year is {:.2f} \".format(df['inventoryTurnover'].mean()))\n",
    "plt.figure(figsize=(15, 7))\n",
    "df['inventoryTurnover'].plot.bar()\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Inventory Turnover')\n",
    "plt.title('Inventory Turnover analysis P&G ')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b16e6765-e469-4963-a153-d8412817cdb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ShortTermAssest'] = df['Cash and cash equivalents'] + df['Cash and short-term investments']+df['Inventories']+df['Average Receivables']\\\n",
    "                        + df['Investments']+df['Investment purchases and sales']+df['Short-term investments']\n",
    "\n",
    "df['liquidcash'] = df['Cash and cash equivalents'] + df['Cash and short-term investments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98200b62-0ebc-43ca-aff9-4f681446b227",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short Term Assets\n",
    "n_year = 5\n",
    "index = np.arange(n_year)\n",
    "bar_width = 0.35\n",
    "opacity = 0.7\n",
    "\n",
    "print(\"Mean of short Term assest for P&G last 5 year is {:.2f} \".format(df['ShortTermAssest'].mean()))\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.bar(index,df['ShortTermAssest'],bar_width,alpha=opacity,color='b',label='Short Term Assest')\n",
    "plt.bar(index+bar_width,df['liquidcash'],bar_width,alpha=opacity,color='g',label='liquid Cash')\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Short Term Assests')\n",
    "plt.title('Short Term Assest or Current Assest analysis P&G ')\n",
    "plt.xticks(index+0.20, df.index)\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9c9c82-871f-47ed-9e92-1c14643fac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Term Asset and Short-Term Asset\n",
    "df['LongTermAsset'] = df['Property, Plant & Equipment Net'] +df['Goodwill and Intangible Assets']+df['Long-term investments']\n",
    "# Long term Asset\n",
    "n_year = 5\n",
    "index = np.arange(n_year)\n",
    "bar_width = 0.3\n",
    "opacity = 0.7\n",
    "\n",
    "print(\"Mean of Long Term assest for P&G last 5 year is {:.2f} \".format(df['LongTermAsset'].mean()))\n",
    "\n",
    "print(\"Mean Percentage Long Term asset out of Total Asset for P&G last 5 year is {:.2f}% \".format((df['LongTermAsset'].mean()/df['Total assets'].mean())*100))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.bar(index,df['LongTermAsset'],bar_width,alpha=opacity,color='b',label='Long Term Asset')\n",
    "plt.bar(index+bar_width,df['ShortTermAssest'],bar_width,alpha=opacity,color='g',label='Short Term Asset')\n",
    "plt.bar(index-bar_width,df['Total assets'],bar_width,alpha=opacity,color='r',label='Total Asset')\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Asset Analysis')\n",
    "plt.title('Short Term Assest and  Long Assest analysis P&G ')\n",
    "plt.xticks(index+0.10, df.index)\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe79874f-a2b3-4511-addd-0de054a3d88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Long Term Asset and Short-Term Asset\n",
    "df['LongTermAsset'] = df['Property, Plant & Equipment Net'] +df['Goodwill and Intangible Assets']+df['Long-term investments']\n",
    "# Long term Asset\n",
    "n_year = 5\n",
    "index = np.arange(n_year)\n",
    "bar_width = 0.3\n",
    "opacity = 0.7\n",
    "\n",
    "print(\"Mean of Long Term assest for P&G last 5 year is {:.2f} \".format(df['LongTermAsset'].mean()))\n",
    "\n",
    "print(\"Mean Percentage Long Term asset out of Total Asset for P&G last 5 year is {:.2f}% \".format((df['LongTermAsset'].mean()/df['Total assets'].mean())*100))\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15, 7))\n",
    "plt.bar(index,df['LongTermAsset'],bar_width,alpha=opacity,color='b',label='Long Term Asset')\n",
    "plt.bar(index+bar_width,df['ShortTermAssest'],bar_width,alpha=opacity,color='g',label='Short Term Asset')\n",
    "plt.bar(index-bar_width,df['Total assets'],bar_width,alpha=opacity,color='r',label='Total Asset')\n",
    "plt.xlabel('Years')\n",
    "plt.ylabel('Asset Analysis')\n",
    "plt.title('Short Term Assest and  Long Assest analysis P&G ')\n",
    "plt.xticks(index+0.10, df.index)\n",
    "plt.grid(False)\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
